{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sympy import symbols, Function, Eq, dsolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuraciones iniciales\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "g = 9.81  # Gravedad en m/s^2\n",
    "num_samples = 5000  # Número de trayectorias\n",
    "\n",
    "# Definir símbolos para sympy\n",
    "t = symbols(\"t\")  # Tiempo\n",
    "vx, vy = Function(\"vx\")(t), Function(\"vy\")(t)  # Velocidades\n",
    "m, c, g = symbols(\"m c g\")  # Parámetros\n",
    "x, y = symbols(\"x y\")  # Posiciones\n",
    "\n",
    "# Ecuaciones diferenciales\n",
    "a_x = Eq(vx.diff(t), -(c / m) * vx)\n",
    "a_y = Eq(vy.diff(t), -g - (c / m) * vy)\n",
    "\n",
    "# Solución de las ecuaciones\n",
    "sol_vx = dsolve(a_x)\n",
    "sol_vy = dsolve(a_y)\n",
    "\n",
    "# Generación de valores aleatorios\n",
    "velocidades_iniciales = np.random.uniform(10, 100, num_samples)  # m/s\n",
    "angulos = np.random.uniform(10, 80, num_samples)  # grados\n",
    "masas = np.random.uniform(0.5, 10, num_samples)  # kg\n",
    "constantes_resistencia = np.random.uniform(0.1, 1.0, num_samples)  # kg/m\n",
    "# Convertir soluciones en funciones para evaluar\n",
    "vx_func = sol_vx.rhs\n",
    "vy_func = sol_vy.rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_trayectoria(v0, theta, m_val, c_val, dt=0.1, max_time=10):\n",
    "    theta_rad = np.radians(theta)  # Convertir ángulo a radianes\n",
    "    vx0 = v0 * np.cos(theta_rad)  # Velocidad inicial en x\n",
    "    vy0 = v0 * np.sin(theta_rad)  # Velocidad inicial en y\n",
    "\n",
    "    # Reemplazar constantes en sympy\n",
    "    vx_t = vx_func.subs({c: c_val, m: m_val}).subs(\"C1\", vx0)\n",
    "    vy_t = vy_func.subs({c: c_val, m: m_val, g: 9.81}).subs(\"C1\", vy0)\n",
    "\n",
    "    # Calcular posiciones\n",
    "    x, y = 0, 0\n",
    "    trayectoria = []\n",
    "\n",
    "    for t_val in np.arange(0, max_time, dt):\n",
    "        vx_eval = vx_t.subs(t, t_val).evalf()\n",
    "        vy_eval = vy_t.subs(t, t_val).evalf()\n",
    "\n",
    "        x += vx_eval * dt\n",
    "        y += vy_eval * dt\n",
    "        trayectoria.append((x, y))\n",
    "\n",
    "        # Detener si toca el suelo\n",
    "        if y < 0:\n",
    "            break\n",
    "    return trayectoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación del dataset\n",
    "data = []\n",
    "for v0, theta, m_val, c_val in zip(\n",
    "    velocidades_iniciales, angulos, masas, constantes_resistencia\n",
    "):\n",
    "    trayectoria = calcular_trayectoria(v0, theta, m_val, c_val)\n",
    "    for punto in trayectoria:\n",
    "        data.append([v0, theta, m_val, c_val, punto[0], punto[1]])\n",
    "        if len(data) >= num_samples:\n",
    "            break  # Detener cuando se alcance el número deseado de registros\n",
    "\n",
    "# Convertir a DataFrame\n",
    "columnas = [\n",
    "    \"velocidad_inicial\",\n",
    "    \"angulo\",\n",
    "    \"masa\",\n",
    "    \"constante_resistencia\",\n",
    "    \"pos_x\",\n",
    "    \"pos_y\",\n",
    "]\n",
    "datos = pd.DataFrame(data[:num_samples], columns=columnas)  # Asegurar 5000 registros\n",
    "\n",
    "# Guardar en CSV\n",
    "datos.to_csv(\"trayectorias_proyectil.csv\", index=False)\n",
    "print(\"Generación de datos completada. Guardado en 'trayectorias_proyectil.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el dataset generado\n",
    "datos = pd.read_csv(\"trayectorias_proyectil.csv\")\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = datos[[\"velocidad_inicial\", \"angulo\", \"masa\", \"constante_resistencia\"]].values\n",
    "y = datos[[\"pos_x\", \"pos_y\"]].values\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ** Anterior\n",
    "# Escalar los datos\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ** anterior estaba 64 - 64\n",
    "# Crear el modelo de red neuronal profunda\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(32, input_dim=4, activation=\"relu\"),\n",
    "        Dense(16, activation=\"relu\", kernel_regularizer=\"l2\"),\n",
    "        Dense(2, activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ** Anterior\n",
    "# Compilar el modelo\n",
    "# model.compile(\n",
    "#    optimizer=Adam(learning_rate=0.001), loss=\"mean_squared_error\", metrics=[\"mae\"]\n",
    "# )\n",
    "\n",
    "model.compile(\n",
    "    optimizer=RMSprop(learning_rate=0.001), loss=\"mean_squared_error\", metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=1024,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Pérdida (Loss): {loss:.4f}, Error Absoluto Medio (MAE): {mae:.4f}\")\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "predicciones = model.predict(X_test)\n",
    "\n",
    "# Calcular métricas de regresión\n",
    "mae_x = mean_absolute_error(y_test[:, 0], predicciones[:, 0])\n",
    "mae_y = mean_absolute_error(y_test[:, 1], predicciones[:, 1])\n",
    "\n",
    "mse_x = mean_squared_error(y_test[:, 0], predicciones[:, 0])\n",
    "mse_y = mean_squared_error(y_test[:, 1], predicciones[:, 1])\n",
    "\n",
    "r2_x = r2_score(y_test[:, 0], predicciones[:, 0])\n",
    "r2_y = r2_score(y_test[:, 1], predicciones[:, 1])\n",
    "\n",
    "print(f\"MAE para pos_x: {mae_x:.4f}, MAE para pos_y: {mae_y:.4f}\")\n",
    "print(f\"MSE para pos_x: {mse_x:.4f}, MSE para pos_y: {mse_y:.4f}\")\n",
    "print(f\"R² para pos_x: {r2_x:.4f}, R² para pos_y: {r2_y:.4f}\")\n",
    "\n",
    "\n",
    "# Precisión personalizada: porcentaje de predicciones dentro de una tolerancia\n",
    "def accuracy_within_tolerance(y_true, y_pred, tolerance=0.1):\n",
    "    diff = np.abs(y_true - y_pred)\n",
    "    within_tolerance = np.all(diff <= tolerance, axis=1)\n",
    "    return np.mean(within_tolerance) * 100\n",
    "\n",
    "\n",
    "accuracy = accuracy_within_tolerance(y_test, predicciones, tolerance=1.0)\n",
    "print(f\"Precisión dentro del rango de tolerancia (1.0 unidades): {accuracy:.2f}%\")\n",
    "\n",
    "# Visualizar las predicciones vs valores reales (pos_x y pos_y separadamente)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Comparar pos_x\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test[:, 0], predicciones[:, 0], alpha=0.5)\n",
    "plt.title(\"Comparación de pos_x (Real vs Predicho)\")\n",
    "plt.xlabel(\"Real\")\n",
    "plt.ylabel(\"Predicho\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Comparar pos_y\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test[:, 1], predicciones[:, 1], alpha=0.5)\n",
    "plt.title(\"Comparación de pos_y (Real vs Predicho)\")\n",
    "plt.xlabel(\"Real\")\n",
    "plt.ylabel(\"Predicho\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Curvas de aprendizaje\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history[\"loss\"], label=\"Pérdida de Entrenamiento\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Pérdida de Validación\")\n",
    "plt.title(\"Curvas de Pérdida durante el Entrenamiento\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Pérdida (Loss)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el dataset\n",
    "try:\n",
    "    data = pd.read_csv(\"trayectorias_proyectil.csv\")\n",
    "except FileNotFoundError:\n",
    "    print(\n",
    "        \"Archivo 'trayectorias_proyectil.csv' no encontrado. Verifica el nombre y la ubicación.\"\n",
    "    )\n",
    "\n",
    "# Verificar que data sea un DataFrame\n",
    "if not isinstance(data, pd.DataFrame):\n",
    "    raise TypeError(\n",
    "        \"El archivo cargado no es un DataFrame. Revisa el proceso de carga.\"\n",
    "    )\n",
    "\n",
    "# Separar características (X) y etiquetas (y)\n",
    "X = data[[\"velocidad_inicial\", \"angulo\", \"masa\", \"constante_resistencia\"]].values\n",
    "y = data[[\"pos_x\", \"pos_y\"]].values\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Crear el modelo\n",
    "model = Sequential(\n",
    "    [\n",
    "        Dense(64, input_dim=4, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(2, activation=\"linear\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005), loss=\"mean_squared_error\", metrics=[\"mae\"]\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=5000,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Pérdida (Loss): {loss:.4f}, Error Absoluto Medio (MAE): {mae * 100:.4f}\")\n",
    "\n",
    "# Predicciones en el conjunto de prueba\n",
    "predicciones = model.predict(X_test)\n",
    "\n",
    "\n",
    "# Calcular precisión\n",
    "def accuracy_within_tolerance(y_true, y_pred, tolerance=1.0):\n",
    "    diff = np.abs(y_true - y_pred)\n",
    "    within_tolerance = np.all(diff <= tolerance, axis=1)\n",
    "    return np.mean(within_tolerance) * 100\n",
    "\n",
    "\n",
    "accuracy = accuracy_within_tolerance(y_test, predicciones, tolerance=5.0)\n",
    "print(f\"Precisión dentro del rango de tolerancia (5.0 unidades): {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "# Calcular métricas de regresión\n",
    "mae_x = mean_absolute_error(y_test[:, 0], predicciones[:, 0])\n",
    "mae_y = mean_absolute_error(y_test[:, 1], predicciones[:, 1])\n",
    "\n",
    "mse_x = mean_squared_error(y_test[:, 0], predicciones[:, 0])\n",
    "mse_y = mean_squared_error(y_test[:, 1], predicciones[:, 1])\n",
    "\n",
    "r2_x = r2_score(y_test[:, 0], predicciones[:, 0])\n",
    "r2_y = r2_score(y_test[:, 1], predicciones[:, 1])\n",
    "\n",
    "print(f\"MAE para pos_x: {mae_x:.4f}, MAE para pos_y: {mae_y:.4f}\")\n",
    "print(f\"MSE para pos_x: {mse_x:.4f}, MSE para pos_y: {mse_y:.4f}\")\n",
    "print(f\"R² para pos_x: {r2_x:.4f}, R² para pos_y: {r2_y:.4f}\")\n",
    "\n",
    "# Visualizar las predicciones vs valores reales (pos_x y pos_y separadamente)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Comparar pos_x\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test[:, 0], predicciones[:, 0], alpha=0.5)\n",
    "plt.title(\"Comparación de pos_x (Real vs Predicho)\")\n",
    "plt.xlabel(\"Real\")\n",
    "plt.ylabel(\"Predicho\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Comparar pos_y\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test[:, 1], predicciones[:, 1], alpha=0.5)\n",
    "plt.title(\"Comparación de pos_y (Real vs Predicho)\")\n",
    "plt.xlabel(\"Real\")\n",
    "plt.ylabel(\"Predicho\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Curvas de aprendizaje\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history[\"loss\"], label=\"Pérdida de Entrenamiento\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Pérdida de Validación\")\n",
    "plt.title(\"Curvas de Pérdida durante el Entrenamiento\")\n",
    "plt.xlabel(\"Épocas\")\n",
    "plt.ylabel(\"Pérdida (Loss)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
